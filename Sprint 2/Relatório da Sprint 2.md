
<h1>- Sprint 2:</h1>
<h4>–  </h4>

<h2>• SQL para Ánalise de Dados do básico ao avançando:</h2>

<h3>- Seção 1:</h3>
<h4>- Na primeira seção do curso "SQL para Análise de Dados do básico ao avançado", tive o acesso aos arquivos do curso em anexo disponibilizado na aula, esse recurso permitiu baixar todos os materiais necessários para acompanhar as lições e praticar.</h4>

 
<h3>- Seção 2:</h3>
<h4>- Nessa parte do curso, configurei o ambiente de trabalho para trabalhar com SQL e análise de dados, isso incluiu a configuração da minha máquina,  tive uma visão geral do pgAdmin e a configuração de um banco de dados, também recebi material de apoio, como documentação e exemplos práticos. </h4>

 
<h3>- Seção 3:</h3>
<h4>- Aprofundei nos comandos básicos, como SELECT, DISTINCT, WHERE, ORDER BY e LIMIT. Aprendi a escrever consultas eficientes, filtrar resultados, ordenar dados e controlar o número de registros retornados. Além disso, enfrentei um desafio prático que me permitiu aplicar o conhecimento adquirido.</h4>

<h3>- Seção 4:</h3>
<h4>- Explorei os operadores no SQL, aprendi sobre os operadores aritméticos, que permitem realizar cálculos matemáticos, como adição e subtração, diretamente nas consultas. Também estudei os operadores de comparação, que são usados para comparar valores e filtrar os resultados com base em condições específicas. Além disso, abordei os operadores lógicos, como AND e OR, que são úteis para combinar condições em consultas mais complexas e no fim fiz um desafio prático.</h4>


<h3>- Seção 5:</h3>
<h4>- Entendi as funções de agregação no SQL, aprendi a utilizar funções como  COUNT, MIN e MAX para realizar cálculos em conjuntos de dados. Também estudei o comando GROUP BY, que me permitiu agrupar os resultados da consulta com base em colunas específicas, além disso, aprendi sobre o comando HAVING, que usei para filtrar os resultados após a aplicação do GROUP BY.</h4>


<h3>- Seção 6:</h3>
<h4>- Obtive conhecimentos sobre os comandos de JOIN no SQL, aprendi sobre os diferentes tipos de Join, como INNER JOIN, LEFT JOIN, RIGHT JOIN e FULL JOIN, e como eles podem ser usados para combinar dados de várias tabelas. Analisei exemplos práticos de como aplicar esses comandos e fiz varias vezes a atividade que está disponível sobre o uso dos Joins. 


<h3>- Seção 7:</h3>
<h4>- Aprendi sobre os comandos de UNION no SQL, descobri como utilizar o UNION para combinar resultados de consultas, o UNION ALL para incluir duplicatas, acompanhei e fiz os exemplos práticos para entender como aplicar esses comandos.</h4>


<h3>- Seção 8:</h3>
<h4>- Estudei sobre subqueries, os tipos e aplicação dessas ferramentas em consultas, com exemplos práticos e um desafio, aprendi que as subqueries podem ser correlacionadas, dependendo dos resultados da consulta principal, ou não correlacionadas.</h4>

<h3>- Seção 9:</h3>
<h4>- Na aula de tratamento de dados, aprendi comandos básicos, conversão de unidades, limpeza e normalização de dados, manipulação de texto, tratamento de datas e uso de funções. </h4>

<h3>- Seção 10:</h3>
<h4>- Sobre manipulação de tabelas, tive a oportunidade de aprender habilidades fundamentais para lidar com dados em um banco de dados. Aprendi como criar tabelas, definindo os nomes das colunas e os tipos de dados adequados, compreendi a importância de aplicar restrições, como chaves primárias e estrangeiras, para garantir a integridade dos dados.</h4>

<h3>- Seção 11:</h3>
<h4>- A aula abordou a criação de um dashboard para acompanhar as vendas de uma empresa, foram apresentadas queries SQL para extrair informações relevantes dos dados de vendas, como total de vendas por período, produtos mais vendidos e clientes mais frequentes. Também foi ensinado como criar gráficos para visualizar os dados de forma mais intuitiva,o objetivo foi desenvolver um dashboard eficiente para análise e monitoramento das vendas.</h4>

<h3>- Seção 12:</h3>
<h4>- Foi a criação de um projeto que teve como objetivo ensinar como analisar o perfil dos clientes por meio de queries SQL e representar os resultados por meio de gráficos, isso possibilita uma compreensão mais clara e visual dos dados de perfil de cliente, auxiliando na identificação de padrões e insights relevantes para a empresa.</h4>

<h3>- Seção 13:</h3>
<h4>- E a ultima seção foi um encerrameto do curso ,no geral o curso me proporcionou uma base sólida em SQL, capacitando-me a realizar análises de dados mais sofisticadas e a obter insights relevantes para os meus projetos. Saio do curso motivado a explorar ainda mais as funcionalidades e recursos do SQL, e continuarei a aperfeiçoar minhas habilidades nessa área em busca de melhorias contínuas em minha prática profissional. </h4>


<h2>• Big Data Fundamentos 3.0:</h2>

<h4>No inicio do curso de Big Data, fui introduzido ao programa e à plataforma de estudo, aprendi a navegar pela plataforma e conheci o conteúdo do curso. Também recebi informações sobre a avaliação final e a conclusão do curso, além disso, ganhei um eBook gratuito da Data Science Academy para complementar meus estudos.</h4>

<h4>Aprendi sobre o que é Big Data, descobri alguns fatos interessantes sobre ele e entendi sua definição,também aprendi sobre os "4 Vs" do Big Data: volume, velocidade, variedade e veracidade. Vi alguns números impressionantes relacionados ao Big Data e entendi a diferença entre Big Data e Ciência de Dados, conheci exemplos de como o Big Data é aplicado em diferentes áreas, no final, fiz um questionário para testar meus conhecimentos.</h4>

<h4> Abordei os sistemas de armazenamento de dados no contexto do Big Data, compreendi a diferença entre bancos de dados relacionais e NoSQL, explorando suas respectivas adequações. Também familiarizei-me com o conceito de data warehouse, um sistema centralizado para armazenar e analisar dados provenientes de várias fontes.
Além disso, descobri os data lakes, que são repositórios flexíveis para armazenamento de dados brutos, e suas vantagens,também adquiri conhecimento sobre data stores, soluções que permitem armazenamento rápido e escalável de dados, por fim explorei os sistemas híbridos de armazenamento, que combinam diversas tecnologias para atender às demandas específicas do Big Data.</h4>


<h4>Mergulhei no mundo do armazenamento e processamento paralelo no contexto do Big Data, explorando o tema, descobri o poder dos clusters de computadores interconectados, capazes de lidar com grandes volumes de dados de forma eficiente, compreendi a importância do armazenamento paralelo, com uma abordagem distribuída que permite acessar e armazenar dados de forma eficiente em um cluster.

Foi fascinante conhecer o Apache Hadoop, um software amplamente utilizado nesse cenário, ele oferece recursos para armazenamento paralelo e processamento distribuído de dados em grande escala. Através do processamento paralelo de Big Data, pude entender como operações simultâneas realizadas em um cluster podem acelerar significativamente o tempo de processamento.

Adentrando na arquitetura de armazenamento e processamento paralelo, ficou claro como diferentes tecnologias e componentes se unem para otimizar o desempenho no processamento de Big Data. Explorar soluções disponíveis no mercado para o armazenamento e processamento paralelo revelou a variedade de opções e abordagens disponíveis para enfrentar os desafios desse campo em constante evolução.</h4>



<h4></h4>



<h4></h4>
<h4></h4>
<h4></h4>
<h4></h4>
<h4></h4>
<h4></h4>




